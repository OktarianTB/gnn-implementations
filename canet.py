# -*- coding: utf-8 -*-
"""CANet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iDg_5KA0PT284te4gha5v99kggkffxY7

# CANet
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as data
import pickle
from PIL import Image
import PIL
import numpy as np
import scipy.misc
import pandas as pd
import matplotlib.pyplot as plt
from torchvision import datasets, transforms
import helper
import random
from torchvision.models import resnet50
from sklearn.metrics import accuracy_score
import os.path


training_data11 = pd.read_excel("./data/Annotation_Base11.xls", header=0, usecols=[0, 2, 3], names=["filename", "retinopathy_grade", "risk_me"])
training_data12 = pd.read_excel("./data/Annotation_Base12.xls", header=0, usecols=[0, 2, 3], names=["filename", "retinopathy_grade", "risk_me"])
training_data13 = pd.read_excel("./data/Annotation_Base13.xls", header=0, usecols=[0, 2, 3], names=["filename", "retinopathy_grade", "risk_me"])
training_data14 = pd.read_excel("./data/Annotation_Base14.xls", header=0, usecols=[0, 2, 3], names=["filename", "retinopathy_grade", "risk_me"])

training_data21 = pd.read_excel("./data/Annotation_Base21.xls", header=0, usecols=[0, 2, 3], names=["filename", "retinopathy_grade", "risk_me"])
training_data22 = pd.read_excel("./data/Annotation_Base22.xls", header=0, usecols=[0, 2, 3], names=["filename", "retinopathy_grade", "risk_me"])
training_data23 = pd.read_excel("./data/Annotation_Base23.xls", header=0, usecols=[0, 2, 3], names=["filename", "retinopathy_grade", "risk_me"])
training_data24 = pd.read_excel("./data/Annotation_Base24.xls", header=0, usecols=[0, 2, 3], names=["filename", "retinopathy_grade", "risk_me"])

training_data31 = pd.read_excel("./data/Annotation_Base31.xls", header=0, usecols=[0, 2, 3], names=["filename", "retinopathy_grade", "risk_me"])
training_data32 = pd.read_excel("./data/Annotation_Base32.xls", header=0, usecols=[0, 2, 3], names=["filename", "retinopathy_grade", "risk_me"])
training_data33 = pd.read_excel("./data/Annotation_Base33.xls", header=0, usecols=[0, 2, 3], names=["filename", "retinopathy_grade", "risk_me"])
training_data34 = pd.read_excel("./data/Annotation_Base34.xls", header=0, usecols=[0, 2, 3], names=["filename", "retinopathy_grade", "risk_me"])

training_data = pd.concat([training_data11, training_data12, training_data13, training_data14, training_data21, training_data22, training_data23, training_data24, training_data31, training_data32, training_data33, training_data34])

partition = [filename.replace(".tif", "") for filename in list(training_data["filename"]) if os.path.exists(f'./data/images/{filename}')]

labels = {}

def get_dr_grade(grade):
    if grade == 0 or grade == 1:
      return 0
    return 1

for i, row in training_data.iterrows():
    id = row["filename"].replace(".tif", "")
    retinopathy_grade = int(row["retinopathy_grade"])
    dme_risk = int(row["risk_me"])

    labels[id] = {"DR": get_dr_grade(retinopathy_grade), "DME": dme_risk}

all_DR_grades = [label["DR"] for label in labels.values()]
num_classes_DR = len(set(all_DR_grades))
print(f"There are {num_classes_DR} DR classes")

all_DME_grades = [label["DME"] for label in labels.values()]
num_classes_DME = len(set(all_DME_grades))
print(f"There are {num_classes_DME} DME classes")

normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
size  = 224

transform_train = transforms.Compose([
        transforms.Resize(256),
        transforms.RandomResizedCrop(size),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ToTensor(),
        normalize,
    ])
            
transform_test = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(size),
        transforms.ToTensor(),
        normalize])

class Dataset(data.Dataset):
    'Characterizes a dataset for PyTorch'
    def __init__(self, list_IDs, labels, transform):
        'Initialization'
        self.filenames = []
        self.labels = labels
        self.transform = transform

        self.images = {}
        for filename in list_IDs:
          try:
            img = self.load_image(filename)
            self.images[filename] = img
            self.filenames.append(filename)
          except FileNotFoundError:
            pass
          except PIL.UnidentifiedImageError:
            pass

        print(f'Loaded {len(self.filenames)} images')

    def __len__(self):
        'Denotes the total number of samples'
        return len(self.filenames)

    def load_image(self, filename):
        # Load data and get label
        image = Image.open(f'./data/images/{filename}.tif').convert("RGB")
        return image
      
    def get_image(self, filename):
      return self.images[filename]

    def __getitem__(self, index):
        'Generates one sample of data'
        # Select sample
        id = self.filenames[index]

        # Load data and get label
        X = self.get_image(id)
        X = self.transform(X)
        Y = self.labels[id]
        
        return X, Y["DR"], Y["DME"]



# Model

class BasicConv(nn.Module):
    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):
        super(BasicConv, self).__init__()
        self.out_channels = out_planes
        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)
        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None
        self.relu = nn.ReLU() if relu else None

    def forward(self, x):
        x = self.conv(x)
        if self.bn is not None:
            x = self.bn(x)
        if self.relu is not None:
            x = self.relu(x)
        return x

class Flatten(nn.Module):
    def forward(self, x):
        return x.view(x.size(0), -1)

class ChannelGate(nn.Module):
    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):
        super(ChannelGate, self).__init__()
        self.gate_channels = gate_channels
        self.mlp = nn.Sequential(
            Flatten(),
            nn.Linear(gate_channels, gate_channels // reduction_ratio),
            nn.ReLU(),
            nn.Linear(gate_channels // reduction_ratio, gate_channels)
            )
        self.pool_types = pool_types
    def forward(self, x):
        channel_att_sum = None
        for pool_type in self.pool_types:
            if pool_type=='avg':
                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))
                channel_att_raw = self.mlp( avg_pool )
            elif pool_type=='max':
                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))
                channel_att_raw = self.mlp( max_pool )
            else:
                pass
            if channel_att_sum is None:
                channel_att_sum = channel_att_raw
            else:
                channel_att_sum = channel_att_sum + channel_att_raw


        scale = torch.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)
        return x * scale

def logsumexp_2d(tensor):
    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)
    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)
    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()
    return outputs


class ChannelPool(nn.Module):
    def forward(self, x):
        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )

class SpatialGate(nn.Module):
    def __init__(self):
        super(SpatialGate, self).__init__()
        kernel_size = 7
        self.compress = ChannelPool()
        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)
    def forward(self, x):
        x_compress = self.compress(x)
        x_out = self.spatial(x_compress)
        scale = torch.sigmoid(x_out) # broadcasting


        return x * scale, scale

class CBAM(nn.Module):
    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):
        super(CBAM, self).__init__()
        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)
        self.no_spatial = no_spatial
        if not no_spatial:
            self.SpatialGate = SpatialGate()
    def forward(self, x):
        x_out = self.ChannelGate(x)
        if not self.no_spatial:
            x_out, scale = self.SpatialGate(x_out)
        return x_out

# CANet Model 

class CANet(nn.Module):
  def __init__(self):
    super(CANet, self).__init__()

    resnet = resnet50(pretrained=True)
    self.resnet_backbone = torch.nn.Sequential(*list(resnet.children())[:-2])

    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
    self.dropout = nn.Dropout(0.3)
    self.branch_bam1 = CBAM(512 * 4)
    self.branch_bam2 = CBAM(512 * 4)
    self.classifier_dep1 = nn.Linear(512 * 4, 1024)
    self.classifier_dep2 = nn.Linear(512 * 4, 1024)
    self.branch_bam3 = CBAM(1024, no_spatial=True)
    self.branch_bam4 = CBAM(1024, no_spatial=True)
    self.classifier1 = nn.Linear(1024, 2)
    self.classifier2 = nn.Linear(1024, 3)
    self.classifier_specific_1 = nn.Linear(1024, 2)
    self.classifier_specific_2 = nn.Linear(1024, 3)

    for m in self.modules():
        if isinstance(m, nn.Conv2d):
            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
            nn.init.constant_(m.weight, 1)
            nn.init.constant_(m.bias, 0)

  def forward(self, x):
    x = self.resnet_backbone(x)
    x = self.dropout(x)
        
    x1 = self.avgpool(self.branch_bam1(x))
    x2 = self.avgpool(self.branch_bam2(x))

    # task specific feature
    x1 = x1.view(x1.size(0), -1)
    x2 = x2.view(x2.size(0), -1)
    x1 = self.classifier_dep1(x1)
    x2 = self.classifier_dep2(x2)

    out1 = self.classifier_specific_1(x1)
    out2 = self.classifier_specific_2(x2)
    
    # learn task correlation
    x1_att = self.branch_bam3(x1.view(x1.size(0), -1, 1, 1))
    x2_att = self.branch_bam4(x2.view(x2.size(0), -1, 1, 1))

    x1_att = x1_att.view(x1_att.size(0), -1)
    x2_att = x2_att.view(x2_att.size(0), -1)

    x1 = torch.stack([x1, x2_att], dim=0).sum(dim=0)
    x2 = torch.stack([x2, x1_att], dim=0).sum(dim=0)

    # final classifier
    x1 = self.classifier1(x1)
    x2 = self.classifier2(x2)

    return x1, x2, out1, out2

"""## Training"""

print("MODEL: CANet - Original v.3 - 3x")

#model_parameters = filter(lambda p: p.requires_grad, model.parameters())
#params = sum([np.prod(p.size()) for p in model_parameters])
#print("Number of params: ", params)


def train(model, loader):
    model.train()
    running_loss = []
    for i, (X, Y_DR, Y_DME) in enumerate(loader):
        X = X.to(device)
        Y_DR = Y_DR.to(device)
        Y_DME = Y_DME.to(device)
        
        optimizer.zero_grad()
        output = model(X)
        
        loss1 = criterion(output[0], Y_DR)
        loss2 = criterion(output[1], Y_DME)

        loss3 = criterion(output[2], Y_DR)
        loss4 = criterion(output[3], Y_DME)
        
        loss = loss1 + loss2 + lambda_value * (loss3 + loss4)

        loss.backward()
        optimizer.step()
        running_loss.append(loss.cpu().detach().numpy())
       
    return np.mean(running_loss)
    
def test(model, loader):
    model.eval()

    all_target_dr = []
    all_target_dme = []
    all_output_dr = []
    all_output_dme = []

    for i, (X, Y_DR, Y_DME) in enumerate(loader):
        X = X.to(device)

        output = model(X)

        output0 = output[0]
        output1 = output[1]
        output0 = torch.softmax(output0, dim=1)
        output1 = torch.softmax(output1, dim=1)

        all_target_dr.append(Y_DR.cpu().data.numpy())
        all_output_dr.append(output0.cpu().data.numpy())
        all_target_dme.append(Y_DME.cpu().data.numpy())
        all_output_dme.append(output1.cpu().data.numpy())

    all_target_dr = [item for sublist in all_target_dr for item in sublist]
    all_output_dr = [item for sublist in all_output_dr for item in sublist]
    all_target_dme = [item for sublist in all_target_dme for item in sublist]
    all_output_dme = [item for sublist in all_output_dme for item in sublist]

    # acc
    acc_dr = accuracy_score(all_target_dr, np.argmax(all_output_dr,axis=1))
    acc_dme = accuracy_score(all_target_dme, np.argmax(all_output_dme, axis=1))

    joint_result = np.vstack((np.argmax(all_output_dr, axis=1), np.argmax(all_output_dme, axis=1)))
    joint_target = np.vstack((all_target_dr, all_target_dme))
    joint_acc = ((np.equal(joint_result, joint_target) == True).sum(axis=0) == 2).sum() / joint_result.shape[1]

    return round(acc_dr, 3), round(acc_dme, 3), round(joint_acc, 3)


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

lambda_value = 0.25
nb_epochs = 1000

all_best_DR_accuracies = []
all_best_DME_accuracies = []
all_best_joint_accuracies = []

for i in range(0, 2):   
    start = i * int(len(partition) * 0.1)
    end = (i+1) * int(len(partition) * 0.1)
    
    print(f"--------------- Iteration {i}: [{start} - {end}] ---------------")
    
    test_dataset = Dataset(partition[start:end], labels, transform_test)
    
    train_partition = list(set(partition) - set(partition[start:end]))
    train_dataset = Dataset(train_partition, labels, transform_train)

    batch_size = 40
    train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
    test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)

    best_DR_accuracy = 0
    best_DME_accuracy = 0
    best_joint_accuracy = 0
    
    model = CANet().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.03)
    criterion = nn.CrossEntropyLoss()

    for epoch in range(nb_epochs):
        loss = train(model, train_loader)
        acc_dr, acc_dme, joint_acc = test(model, test_loader)

        if epoch % 20 == 0:
            print(f"Epoch {epoch} - Loss: {loss} - Accuracy DR: {acc_dr} - Accuracy DME: {acc_dme}, - Joint Accuracy: {joint_acc}")

        if joint_acc > best_joint_accuracy:
          best_joint_accuracy = joint_acc
          best_DR_accuracy = acc_dr
          best_DME_accuracy = acc_dme

    print(f"Best joint accuracy: {best_joint_accuracy} - Best DR accuracy: {best_DR_accuracy} -  Best DME accuracy: {best_DME_accuracy}\n\n")
    all_best_DR_accuracies.append(best_DR_accuracy)
    all_best_DME_accuracies.append(best_DME_accuracy)
    all_best_joint_accuracies.append(best_joint_accuracy)


print(all_best_DR_accuracies)
print(all_best_DME_accuracies)
print(all_best_joint_accuracies)

print(f"DR accuracy: {sum(all_best_DR_accuracies) / len(all_best_DR_accuracies)}")
print(f"DME accuracy: {sum(all_best_DME_accuracies) / len(all_best_DME_accuracies)}")
print(f"Joint accuracy: {sum(all_best_joint_accuracies) / len(all_best_joint_accuracies)}")


