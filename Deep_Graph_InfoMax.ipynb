{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Graph InfoMax.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW29WrOxhilO"
      },
      "source": [
        "# Implementation of Deep Graph InfoMax\n",
        "\n",
        "Based upon:\n",
        "- **Paper:** Deep Graph Infomax (Veličković et al., ICLR 2019) https://arxiv.org/pdf/1809.10341.pdf\n",
        "\n",
        "- **Implementation:** https://github.com/PetarV-/DGI\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syZw3vBuhx9f"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import pickle as pkl\n",
        "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
        "import sys\n",
        "import networkx as nx"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdf3BtAnh-xs"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FmC56o4_FTS"
      },
      "source": [
        "def parse_index_file(filename):\n",
        "    \"\"\"Parse index file.\"\"\"\n",
        "    index = []\n",
        "    for line in open(filename):\n",
        "        index.append(int(line.strip()))\n",
        "    return index\n",
        "\n",
        "def sample_mask(idx, l):\n",
        "    \"\"\"Create mask.\"\"\"\n",
        "    mask = np.zeros(l)\n",
        "    mask[idx] = 1\n",
        "    return np.array(mask, dtype=np.bool)\n",
        "\n",
        "def load_data(path): \n",
        "    \"\"\"Load data.\"\"\"\n",
        "    names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
        "    objects = []\n",
        "    dataset_str = \"cora\"\n",
        "    for i in range(len(names)):\n",
        "        with open(\"{}/ind.{}.{}\".format(path, dataset_str, names[i]), 'rb') as f:\n",
        "            if sys.version_info > (3, 0):\n",
        "                objects.append(pkl.load(f, encoding='latin1'))\n",
        "            else:\n",
        "                objects.append(pkl.load(f))\n",
        "\n",
        "    x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
        "    test_idx_reorder = parse_index_file(\"{}/ind.{}.test.index\".format(path, dataset_str))\n",
        "    test_idx_range = np.sort(test_idx_reorder)\n",
        "\n",
        "    features = sp.vstack((allx, tx)).tolil()\n",
        "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
        "\n",
        "    labels = np.vstack((ally, ty))\n",
        "    labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
        "\n",
        "    idx_test = test_idx_range.tolist()\n",
        "    idx_train = range(len(y))\n",
        "    idx_val = range(len(y), len(y)+500)\n",
        "\n",
        "    return adj, features, labels, idx_train, idx_val, idx_test\n",
        "\n",
        "def sparse_to_tuple(sparse_mx, insert_batch=False):\n",
        "    \"\"\"Convert sparse matrix to tuple representation.\"\"\"\n",
        "    \"\"\"Set insert_batch=True if you want to insert a batch dimension.\"\"\"\n",
        "    def to_tuple(mx):\n",
        "        if not sp.isspmatrix_coo(mx):\n",
        "            mx = mx.tocoo()\n",
        "        if insert_batch:\n",
        "            coords = np.vstack((np.zeros(mx.row.shape[0]), mx.row, mx.col)).transpose()\n",
        "            values = mx.data\n",
        "            shape = (1,) + mx.shape\n",
        "        else:\n",
        "            coords = np.vstack((mx.row, mx.col)).transpose()\n",
        "            values = mx.data\n",
        "            shape = mx.shape\n",
        "        return coords, values, shape\n",
        "\n",
        "    if isinstance(sparse_mx, list):\n",
        "        for i in range(len(sparse_mx)):\n",
        "            sparse_mx[i] = to_tuple(sparse_mx[i])\n",
        "    else:\n",
        "        sparse_mx = to_tuple(sparse_mx)\n",
        "\n",
        "    return sparse_mx\n",
        "\n",
        "def standardize_data(f, train_mask):\n",
        "    \"\"\"Standardize feature matrix and convert to tuple representation\"\"\"\n",
        "    # standardize data\n",
        "    f = f.todense()\n",
        "    mu = f[train_mask == True, :].mean(axis=0)\n",
        "    sigma = f[train_mask == True, :].std(axis=0)\n",
        "    f = f[:, np.squeeze(np.array(sigma > 0))]\n",
        "    mu = f[train_mask == True, :].mean(axis=0)\n",
        "    sigma = f[train_mask == True, :].std(axis=0)\n",
        "    f = (f - mu) / sigma\n",
        "    return f\n",
        "\n",
        "def preprocess_features(features):\n",
        "    \"\"\"Row-normalize feature matrix and convert to tuple representation\"\"\"\n",
        "    rowsum = np.array(features.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    features = r_mat_inv.dot(features)\n",
        "    return features.todense(), sparse_to_tuple(features)\n",
        "\n",
        "def normalize_adj(adj):\n",
        "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    rowsum = np.array(adj.sum(1))\n",
        "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
        "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
        "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
        "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
        "\n",
        "\n",
        "def preprocess_adj(adj):\n",
        "    \"\"\"Preprocessing of adjacency matrix for simple GCN model and conversion to tuple representation.\"\"\"\n",
        "    adj_normalized = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
        "    return sparse_to_tuple(adj_normalized)\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itYfDS6jiEJ9"
      },
      "source": [
        "## Deep Graph InfoMax Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDG-A63Sicpl"
      },
      "source": [
        "### GCN Model\n",
        "\n",
        "We define an encoder $ \\mathcal{E}:\\mathcal{R}^{N\\times F}\\times\\mathcal{R}^{N\\times N}\\rightarrow \\mathcal{R}^{N\\times F'}$ such that $ \\mathcal{E}(X,A)=H=\\{\\vec{h}_1, \\vec{h}_2,.., \\vec{h}_N\\}$ represents high-level representations $\\vec{h}_i\\in \\mathcal{R}^{F'} $ for each node $i$.\n",
        "\n",
        "\n",
        "Here, we use the **GCN layer** ([Kipf et al. (2017)](https://arxiv.org/abs/1609.02907)) defined as: $ \\mathcal{E}(X,A)=\\sigma(\\hat{D}^{-1/2}\\hat{A}\\hat{D}^{-1/2}X\\Theta)\n",
        "$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nYyb3aphyVO"
      },
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_ft, out_ft, bias=True):\n",
        "        super(GCN, self).__init__()\n",
        "        self.fc = nn.Linear(in_ft, out_ft, bias=False)\n",
        "        self.act = nn.PReLU()\n",
        "        \n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.FloatTensor(out_ft))\n",
        "            self.bias.data.fill_(0.0)\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        for m in self.modules():\n",
        "            self.weights_init(m)\n",
        "\n",
        "    def weights_init(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.fill_(0.0)\n",
        "\n",
        "    # Shape of seq: (batch, nodes, features)\n",
        "    def forward(self, seq, adj, sparse=False):\n",
        "        seq_fts = self.fc(seq)\n",
        "        if sparse:\n",
        "            out = torch.unsqueeze(torch.spmm(adj, torch.squeeze(seq_fts, 0)), 0)\n",
        "        else:\n",
        "            out = torch.bmm(adj, seq_fts)\n",
        "        if self.bias is not None:\n",
        "            out += self.bias\n",
        "        \n",
        "        return self.act(out)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgzoQug9l_UE"
      },
      "source": [
        "### Readout Function\n",
        "We leverage a readout function $\\mathcal{R}:\\mathbb{R} ^{N\\times F}\\rightarrow \\mathbb{R}^F$ and use it to summarize the obtained patch representations into a graph-level representation, i.e. $\\vec{s}=\\mathcal{R}(\\mathcal{E}(X,A))$.\n",
        "\n",
        "We use a simple averaging of all the nodes' features: $ \\mathcal{R}(H)=\\sigma(\\frac{1}{N}\\sum_{i=1}^N\\vec{h}_i) $."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T222DLqjiRWA"
      },
      "source": [
        "class AvgReadout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AvgReadout, self).__init__()\n",
        "\n",
        "    def forward(self, seq, msk):\n",
        "        if msk is None:\n",
        "            return torch.mean(seq, 1)\n",
        "        else:\n",
        "            msk = torch.unsqueeze(msk, -1)\n",
        "            return torch.sum(seq * msk, 1) / torch.sum(msk)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB5qVS0amkGz"
      },
      "source": [
        "### Discriminator Function\n",
        "\n",
        "As a proxy for maximizing the local mutual information, we employ a discriminator $\\mathcal{D}:\\mathbb{R}^F\\times \\mathbb{R}^F\\rightarrow \\mathbb{R}$ such that $\\mathcal{D}(\\vec{h}_i,\\vec{s})$ represents the probability scores assigned to this patch-summary pair.\n",
        "\n",
        "Negative samples for $\\mathcal{D}$ are provided by pairing the summary $\\vec{s}$ from $(X,A)$ with patch representations $\\vec{\\tilde{h}}_j$ of an alternative graph $(\\tilde{X},\\tilde{A})$:\n",
        "\n",
        "- In a multi-graph setting, such graphs may be obtained as other elements of a training set\n",
        "- For a single graph, an explicit corruption function is required to obtain a negative example from the original graph\n",
        "\n",
        "Here, we score summary-patch representation pairs by applying a simple bilinear scoring function with W as a learnable scoring matrix: $D(\\vec{h}_i,\\vec{s})=\\sigma(\\vec{h}_i^TW\\vec{s})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFOZDA2XiRYc"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, n_h):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.f_k = nn.Bilinear(n_h, n_h, 1)\n",
        "\n",
        "        for m in self.modules():\n",
        "            self.weights_init(m)\n",
        "\n",
        "    def weights_init(self, m):\n",
        "        if isinstance(m, nn.Bilinear):\n",
        "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.fill_(0.0)\n",
        "\n",
        "    def forward(self, c, h_pl, h_mi, s_bias1=None, s_bias2=None):\n",
        "        c_x = torch.unsqueeze(c, 1)\n",
        "        c_x = c_x.expand_as(h_pl)\n",
        "\n",
        "        sc_1 = torch.squeeze(self.f_k(h_pl, c_x), 2)\n",
        "        sc_2 = torch.squeeze(self.f_k(h_mi, c_x), 2)\n",
        "\n",
        "        if s_bias1 is not None:\n",
        "            sc_1 += s_bias1\n",
        "        if s_bias2 is not None:\n",
        "            sc_2 += s_bias2\n",
        "\n",
        "        logits = torch.cat((sc_1, sc_2), 1)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x34Jx830nou3"
      },
      "source": [
        "## Deep Graph InfoMax Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAsZLHwmpb40"
      },
      "source": [
        "### DGI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxaLknztiRaw"
      },
      "source": [
        "class DGI(nn.Module):\n",
        "    def __init__(self, n_in, n_h):\n",
        "        super(DGI, self).__init__()\n",
        "        self.gcn = GCN(n_in, n_h)\n",
        "        self.read = AvgReadout()\n",
        "\n",
        "        self.sigm = nn.Sigmoid()\n",
        "\n",
        "        self.disc = Discriminator(n_h)\n",
        "\n",
        "    def forward(self, seq1, seq2, adj, sparse, msk, samp_bias1, samp_bias2):\n",
        "        h_1 = self.gcn(seq1, adj, sparse)\n",
        "\n",
        "        c = self.read(h_1, msk)\n",
        "        c = self.sigm(c)\n",
        "\n",
        "        h_2 = self.gcn(seq2, adj, sparse)\n",
        "\n",
        "        ret = self.disc(c, h_1, h_2, samp_bias1, samp_bias2)\n",
        "\n",
        "        return ret\n",
        "\n",
        "    # Detach the return variables\n",
        "    def embed(self, seq, adj, sparse, msk):\n",
        "        h_1 = self.gcn(seq, adj, sparse)\n",
        "        c = self.read(h_1, msk)\n",
        "\n",
        "        return h_1.detach(), c.detach()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnwpR1ZhsgqA"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX8f1FA2iRdI"
      },
      "source": [
        "class LogReg(nn.Module):\n",
        "    def __init__(self, ft_in, nb_classes):\n",
        "        super(LogReg, self).__init__()\n",
        "        self.fc = nn.Linear(ft_in, nb_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            self.weights_init(m)\n",
        "\n",
        "    def weights_init(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.fill_(0.0)\n",
        "\n",
        "    def forward(self, seq):\n",
        "        ret = self.fc(seq)\n",
        "        return ret\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV-Sa8ETz3FF"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U48HjWiez6h0",
        "outputId": "1bdcc5b0-cab4-458e-a89f-23785aa8ad66"
      },
      "source": [
        "# Load data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"./drive/MyDrive/Colab Notebooks/Representation Learning for GNNs/data/cora/\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCAqY8aQz6pp"
      },
      "source": [
        "adj, features, labels, idx_train, idx_val, idx_test = load_data(path)\n",
        "features, _ = preprocess_features(features)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0E2x7T7s0j3"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NskxgS1hyX2"
      },
      "source": [
        "args = {\n",
        "    \"device\" : 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    \"epochs\" : 500,\n",
        "    \"patience\": 20,\n",
        "    \"lr\" : 0.001,\n",
        "    \"weight_decay\": 0.0,\n",
        "    \"dropout\": 0.0,\n",
        "    \"hidden\" : 512,\n",
        "    \"batch_size\": 1,\n",
        "    \"sparse\": True\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SdRBy2ahyaV"
      },
      "source": [
        "nb_nodes = features.shape[0]\n",
        "ft_size = features.shape[1]\n",
        "nb_classes = labels.shape[1]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5K57fIhEy0y"
      },
      "source": [
        "adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
        "\n",
        "if args[\"sparse\"]:\n",
        "    sp_adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
        "else:\n",
        "    adj = (adj + sp.eye(adj.shape[0])).todense()\n",
        "\n",
        "features = torch.FloatTensor(features[np.newaxis])\n",
        "if not args[\"sparse\"]:\n",
        "    adj = torch.FloatTensor(adj[np.newaxis])\n",
        "labels = torch.FloatTensor(labels[np.newaxis])\n",
        "idx_train = torch.LongTensor(idx_train)\n",
        "idx_val = torch.LongTensor(idx_val)\n",
        "idx_test = torch.LongTensor(idx_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXnx27gSE8fo"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('Using CUDA')\n",
        "    features = features.cuda()\n",
        "    if args[\"sparse\"]:\n",
        "        sp_adj = sp_adj.cuda()\n",
        "    else:\n",
        "        adj = adj.cuda()\n",
        "    labels = labels.cuda()\n",
        "    idx_train = idx_train.cuda()\n",
        "    idx_val = idx_val.cuda()\n",
        "    idx_test = idx_test.cuda()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89n-jdAruOI_"
      },
      "source": [
        "b_xent = nn.BCEWithLogitsLoss()\n",
        "xent = nn.CrossEntropyLoss()\n",
        "cnt_wait = 0\n",
        "best = 1e9\n",
        "best_t = 0\n",
        "batch_size = 1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8ZLlFuStdrt"
      },
      "source": [
        "model = DGI(ft_size, args[\"hidden\"]).to(args[\"device\"])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args[\"lr\"], weight_decay=args[\"weight_decay\"])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBB52lVzuYWX",
        "outputId": "d778de94-f1f8-4c13-898e-2b5d8a911fd6"
      },
      "source": [
        "for epoch in range(args[\"epochs\"] + 1):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  idx = np.random.permutation(nb_nodes)\n",
        "  shuf_fts = features[:, idx, :]\n",
        "\n",
        "  lbl_1 = torch.ones(batch_size, nb_nodes)\n",
        "  lbl_2 = torch.zeros(batch_size, nb_nodes)\n",
        "  lbl = torch.cat((lbl_1, lbl_2), 1)\n",
        "\n",
        "  shuf_fts = shuf_fts.to(args[\"device\"])\n",
        "  lbl = lbl.to(args[\"device\"])\n",
        "  \n",
        "  logits = model(features, shuf_fts, sp_adj if args[\"sparse\"] else adj, args[\"sparse\"], None, None, None) \n",
        "  loss = b_xent(logits, lbl)\n",
        "  \n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Epoch: {epoch} - Loss: {loss.cpu().detach().numpy()}')\n",
        "\n",
        "  if loss < best:\n",
        "      best = loss\n",
        "      best_t = epoch\n",
        "      cnt_wait = 0\n",
        "      torch.save(model.state_dict(), 'best_dgi.pkl')\n",
        "  else:\n",
        "      cnt_wait += 1\n",
        "\n",
        "  if cnt_wait == args[\"patience\"]:\n",
        "      print('Early stopping!')\n",
        "      break\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 - Loss: 0.6931074261665344\n",
            "Epoch: 10 - Loss: 0.6414570212364197\n",
            "Epoch: 20 - Loss: 0.5115184187889099\n",
            "Epoch: 30 - Loss: 0.3741282522678375\n",
            "Epoch: 40 - Loss: 0.2765086889266968\n",
            "Epoch: 50 - Loss: 0.22733454406261444\n",
            "Epoch: 60 - Loss: 0.1932801753282547\n",
            "Epoch: 70 - Loss: 0.15830954909324646\n",
            "Epoch: 80 - Loss: 0.14913277328014374\n",
            "Epoch: 90 - Loss: 0.13185185194015503\n",
            "Epoch: 100 - Loss: 0.11653786152601242\n",
            "Epoch: 110 - Loss: 0.11042811721563339\n",
            "Epoch: 120 - Loss: 0.10591542720794678\n",
            "Epoch: 130 - Loss: 0.09473607689142227\n",
            "Epoch: 140 - Loss: 0.09520158916711807\n",
            "Epoch: 150 - Loss: 0.08930528163909912\n",
            "Epoch: 160 - Loss: 0.08331979811191559\n",
            "Epoch: 170 - Loss: 0.0773174986243248\n",
            "Epoch: 180 - Loss: 0.06864462792873383\n",
            "Epoch: 190 - Loss: 0.07126422226428986\n",
            "Epoch: 200 - Loss: 0.06315848976373672\n",
            "Epoch: 210 - Loss: 0.05941636115312576\n",
            "Epoch: 220 - Loss: 0.06072395294904709\n",
            "Early stopping!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8WYPJUcwHwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29f81ac-c2ed-45ce-cb18-ae0a3aa60d46"
      },
      "source": [
        "print('Loading {}th epoch'.format(best_t))\n",
        "model.load_state_dict(torch.load('best_dgi.pkl'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading 205th epoch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85qRWEJSwHzH"
      },
      "source": [
        "embeds, _ = model.embed(features, sp_adj if args[\"sparse\"] else adj, args[\"sparse\"], None)\n",
        "train_embs = embeds[0, idx_train]\n",
        "val_embs = embeds[0, idx_val]\n",
        "test_embs = embeds[0, idx_test]\n",
        "\n",
        "train_lbls = torch.argmax(labels[0, idx_train], dim=1)\n",
        "val_lbls = torch.argmax(labels[0, idx_val], dim=1)\n",
        "test_lbls = torch.argmax(labels[0, idx_test], dim=1)\n",
        "\n",
        "tot = torch.zeros(1)\n",
        "\n",
        "accs = []"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCYwbFoSwH1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da366a43-a501-4075-e38e-3aa3d140bd1f"
      },
      "source": [
        "for index in range(50):\n",
        "    log = LogReg(args[\"hidden\"], nb_classes)\n",
        "    opt = torch.optim.Adam(log.parameters(), lr=0.01, weight_decay=0.0)\n",
        "\n",
        "    pat_steps = 0\n",
        "    best_acc = torch.zeros(1)\n",
        "    for _ in range(100):\n",
        "        log.train()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        logits = log(train_embs)\n",
        "        loss = xent(logits, train_lbls)\n",
        "        \n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    logits = log(test_embs)\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    acc = torch.sum(preds == test_lbls).float() / test_lbls.shape[0]\n",
        "    accs.append(acc * 100)\n",
        "    tot += acc\n",
        "\n",
        "print('Average accuracy:', tot / 50)\n",
        "\n",
        "accs = torch.stack(accs)\n",
        "print(accs.mean())\n",
        "print(accs.std())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average accuracy: tensor([0.8091])\n",
            "tensor(80.9100)\n",
            "tensor(0.1474)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ru5RIXkwH4i"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}